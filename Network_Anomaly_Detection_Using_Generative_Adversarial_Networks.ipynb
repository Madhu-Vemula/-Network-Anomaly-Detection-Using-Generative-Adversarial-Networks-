{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Madhu-Vemula/-Network-Anomaly-Detection-Using-Generative-Adversarial-Networks-/blob/main/Network_Anomaly_Detection_Using_Generative_Adversarial_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 1: Loading and Preprocessing Data**"
      ],
      "metadata": {
        "id": "fyCU84v863fL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import logging\n",
        "\n",
        "# Suppressing the warning\n",
        "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "print(\"Loading and preprocessing the dataset...\")\n",
        "print(\"Done\")\n",
        "dataset_path = \"/content/drive/MyDrive/MINI 1/KDDTrain.csv\"\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(dataset_path, nrows=1000)\n",
        "\n",
        "# Encode categorical features\n",
        "print(\"Encoding categorical features...\")\n",
        "print(\"Done\")\n",
        "categorical_cols = ['protocol_type', 'service', 'flag', 'label']\n",
        "for col in categorical_cols:\n",
        "    df[col] = pd.factorize(df[col])[0]\n",
        "\n",
        "# Scale numerical features\n",
        "print(\"Scaling numerical features...\")\n",
        "print(\"Done\")\n",
        "scaler = StandardScaler()\n",
        "numerical_cols = [col for col in df.columns if col not in categorical_cols]\n",
        "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
        "\n",
        "# Split dataset into train and test sets\n",
        "print(\"Splitting dataset into train and test sets...\")\n",
        "print(\"Done\")\n",
        "X_train, X_test = train_test_split(df.values, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJR4vtkk66Sk",
        "outputId": "ac57957d-7054-4d35-cd28-d038bdf730b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Loading and preprocessing the dataset...\n",
            "Done\n",
            "Encoding categorical features...\n",
            "Done\n",
            "Scaling numerical features...\n",
            "Done\n",
            "Splitting dataset into train and test sets...\n",
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 2: Model Definition and Training**"
      ],
      "metadata": {
        "id": "V-Rym1N47Rh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "\n",
        "# Define the generator model with increased complexity\n",
        "def build_generator(latent_dim, output_dim):\n",
        "    input_layer = Input(shape=(latent_dim,))\n",
        "    x = Dense(256, activation='relu')(input_layer)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(output_dim, activation='tanh')(x)\n",
        "    generator = Model(input_layer, x)\n",
        "    return generator\n",
        "\n",
        "# Define the discriminator model with increased complexity\n",
        "def build_discriminator(input_dim):\n",
        "    input_layer = Input(shape=(input_dim,))\n",
        "    x = Dense(256, activation='relu')(input_layer)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(1, activation='sigmoid')(x)\n",
        "    discriminator = Model(input_layer, x)\n",
        "    discriminator.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002), metrics=['accuracy'])\n",
        "    return discriminator\n",
        "\n",
        "\n",
        "# Define a function to train the GAN with adjusted loss weight\n",
        "def train_gan(generator, discriminator, gan, X_train, latent_dim, epochs, batch_size, loss_weight):\n",
        "    train_accuracy = []\n",
        "    test_accuracy = []\n",
        "    for epoch in range(epochs):\n",
        "        # Train discriminator\n",
        "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "        gen_data = generator.predict(noise)\n",
        "        real_data = X_train[np.random.randint(0, X_train.shape[0], batch_size)]\n",
        "        discriminator_loss_real = discriminator.train_on_batch(real_data, np.ones((batch_size, 1)))\n",
        "        discriminator_loss_fake = discriminator.train_on_batch(gen_data, np.zeros((batch_size, 1)))\n",
        "        discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
        "\n",
        "        # Train generator\n",
        "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "        generator_loss = gan.train_on_batch(noise, np.ones((batch_size, 1)))\n",
        "\n",
        "        # Print progress\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Epoch {epoch}/{epochs}, Discriminator Loss: {discriminator_loss[0]}, Generator Loss: {generator_loss}\")\n",
        "\n",
        "        # Evaluate model accuracy\n",
        "        if epoch % 5 == 0:\n",
        "            train_accuracy.append(evaluate_accuracy(generator, discriminator, X_train, batch_size))\n",
        "            # test_accuracy.append(evaluate_accuracy(generator, discriminator, X_test, batch_size))\n",
        "            print(f\"Epoch {epoch}/{epochs}, Train Accuracy: {train_accuracy[-1]}\")\n",
        "            # print(f\"Epoch {epoch}/{epochs}, Test Accuracy: {test_accuracy[-1]}\")\n",
        "\n",
        "    return train_accuracy, test_accuracy\n",
        "\n",
        "# Combine generator and discriminator into a GAN model with adjusted loss weight\n",
        "def build_gan(generator, discriminator, loss_weight):\n",
        "    discriminator.trainable = False\n",
        "    gan_input = Input(shape=(latent_dim,))\n",
        "    gan_output = discriminator(generator(gan_input))\n",
        "    gan = Model(gan_input, gan_output)\n",
        "    gan.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy', loss_weights=loss_weight)\n",
        "    return gan\n",
        "\n",
        "# Set hyperparameters\n",
        "latent_dim = 20\n",
        "output_dim = df.shape[1]  # Assuming df is defined and contains the dataset\n",
        "epochs = 100\n",
        "batch_size = 512\n",
        "loss_weight = 0.75\n",
        "\n",
        "# Build generator and discriminator\n",
        "generator = build_generator(latent_dim, output_dim)\n",
        "discriminator = build_discriminator(output_dim)\n",
        "\n",
        "# Save generator and discriminator models to Google Drive\n",
        "generator.save(\"/content/drive/MyDrive/MINI 1/generator_model.h5\")\n",
        "discriminator.save(\"/content/drive/MyDrive/MINI 1/discriminator_model.h5\")\n",
        "print(\"Models Saved Successfully....\")\n"
      ],
      "metadata": {
        "id": "oAI8JRO27SWq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18acc76f-015d-4737-a68e-64cce082dc75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models Saved Successfully....\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 3: Evaluation and Visualization**"
      ],
      "metadata": {
        "id": "GG54jLt8oavm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to evaluate model accuracy\n",
        "def evaluate_accuracy(generator, discriminator, X_data, batch_size):\n",
        "    noise = np.random.normal(0, 1, (X_data.shape[0], latent_dim))\n",
        "    gen_data = generator.predict(noise)\n",
        "    real_data = X_data[np.random.randint(0, X_data.shape[0], batch_size)]\n",
        "    synthetic_labels = np.zeros((X_data.shape[0], 1))\n",
        "    real_labels = np.ones((batch_size, 1))\n",
        "    discriminator_accuracy = accuracy_score(np.concatenate([np.ones((batch_size,)), np.zeros((X_data.shape[0]))]),\n",
        "                                             np.concatenate([discriminator.predict(real_data).ravel() >= 0.5, discriminator.predict(gen_data).ravel() >= 0.5]))\n",
        "    return discriminator_accuracy\n",
        "\n",
        "# Set hyperparameters\n",
        "print(\"Setting hyperparameters...\")\n",
        "latent_dim = 20\n",
        "batch_size = 512\n",
        "epochs = 100\n",
        "loss_weight = 0.75\n",
        "\n",
        "# Rebuild and compile the models with modified architecture and loss weight\n",
        "print(\"Building and compiling the models...\")\n",
        "generator = build_generator(latent_dim, df.shape[1])\n",
        "discriminator = build_discriminator(df.shape[1])\n",
        "gan = build_gan(generator, discriminator, loss_weight)\n",
        "\n",
        "# Train the GAN with adjusted loss weight\n",
        "print(\"Training the GAN...\")\n",
        "train_accuracy, test_accuracy = train_gan(generator, discriminator, gan, X_train, latent_dim, epochs, batch_size, loss_weight)\n",
        "\n"
      ],
      "metadata": {
        "id": "g8GHLPnPoZ_B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16f490b5-0183-42c4-df17-8b91df0ab845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting hyperparameters...\n",
            "Building and compiling the models...\n",
            "Training the GAN...\n",
            "16/16 [==============================] - 1s 3ms/step\n",
            "Epoch 0/100, Discriminator Loss: 0.6655756831169128, Generator Loss: 0.46752357482910156\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "Epoch 0/100, Train Accuracy: 0.3719512195121951\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "Epoch 5/100, Train Accuracy: 0.39253048780487804\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "Epoch 10/100, Discriminator Loss: 0.5233138203620911, Generator Loss: 0.4397878646850586\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "Epoch 10/100, Train Accuracy: 0.4169207317073171\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "Epoch 15/100, Train Accuracy: 0.5823170731707317\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "Epoch 20/100, Discriminator Loss: 0.45878664404153824, Generator Loss: 0.4424753189086914\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "Epoch 20/100, Train Accuracy: 0.9283536585365854\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "Epoch 25/100, Train Accuracy: 0.9839939024390244\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "Epoch 30/100, Discriminator Loss: 0.41094178706407547, Generator Loss: 0.4653846323490143\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "Epoch 30/100, Train Accuracy: 0.9908536585365854\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "Epoch 35/100, Train Accuracy: 0.9786585365853658\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "Epoch 40/100, Discriminator Loss: 0.3888697288930416, Generator Loss: 0.5030081272125244\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 3ms/step\n",
            "Epoch 40/100, Train Accuracy: 0.9390243902439024\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "Epoch 45/100, Train Accuracy: 0.90625\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "Epoch 50/100, Discriminator Loss: 0.38580625504255295, Generator Loss: 0.5287004709243774\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "Epoch 50/100, Train Accuracy: 0.9245426829268293\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "Epoch 55/100, Train Accuracy: 0.9626524390243902\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "Epoch 60/100, Discriminator Loss: 0.36560744047164917, Generator Loss: 0.5868294835090637\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "Epoch 60/100, Train Accuracy: 0.9817073170731707\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "Epoch 65/100, Train Accuracy: 0.9916158536585366\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "Epoch 70/100, Discriminator Loss: 0.3385656177997589, Generator Loss: 0.6160159111022949\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "Epoch 70/100, Train Accuracy: 0.993140243902439\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "Epoch 75/100, Train Accuracy: 0.9923780487804879\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "Epoch 80/100, Discriminator Loss: 0.28557440638542175, Generator Loss: 0.7001182436943054\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "Epoch 80/100, Train Accuracy: 0.9824695121951219\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "Epoch 85/100, Train Accuracy: 0.9824695121951219\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "Epoch 90/100, Discriminator Loss: 0.3211483806371689, Generator Loss: 0.6564996242523193\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "Epoch 90/100, Train Accuracy: 0.9420731707317073\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "Epoch 95/100, Train Accuracy: 0.8559451219512195\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 4: Classification Report and Analysis**"
      ],
      "metadata": {
        "id": "lSRonHEF4GCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the trained GAN for anomaly detection\n",
        "print(\"Using the trained GAN for anomaly detection...\")\n",
        "# Generate synthetic data using the generator\n",
        "synthetic_data = generator.predict(np.random.normal(0, 1, size=(len(df), latent_dim)))\n",
        "\n",
        "# Calculate anomaly scores\n",
        "print(\"Calculating anomaly scores...\")\n",
        "anomaly_scores = np.mean(np.abs(synthetic_data - df.values), axis=1)\n",
        "\n",
        "# Set threshold for anomaly detection\n",
        "threshold = np.percentile(anomaly_scores, 96)\n",
        "\n",
        "# Detect anomalies\n",
        "print(\"Detecting anomalies...\")\n",
        "predicted_labels = anomaly_scores > threshold\n",
        "\n",
        "# Calculate confusion matrix\n",
        "print(\"Calculating confusion matrix...\")\n",
        "tn, fp, fn, tp = confusion_matrix(df['label'] == 4, predicted_labels).ravel()\n",
        "\n",
        "# Count and classify anomalies\n",
        "print(\"Counting and classifying anomalies...\")\n",
        "anomaly_count = {}\n",
        "for i in range(len(df.columns) - 1):\n",
        "    count = df[df['label'] == i].shape[0]\n",
        "    if count > 0:\n",
        "        if i == 0:\n",
        "            anomaly_count['Normal (attack_type 4)'] = count\n",
        "        elif i == 15:\n",
        "            anomaly_count['DoS (attack_type 15)'] = count\n",
        "        elif i == 0:\n",
        "            anomaly_count['Probe (attack_type 0)'] = count\n",
        "        elif i == 9:\n",
        "            anomaly_count['User-to-Root (attack_type 9)'] = count\n",
        "        elif i == 10:\n",
        "            anomaly_count['RemoteAccess (attack_type 10)'] = count\n",
        "        elif i == 20:\n",
        "            anomaly_count['WarezClient (attack_type 20)'] = count\n",
        "        elif i == 8:\n",
        "            anomaly_count['RootKit (attack_type 8)'] = count\n",
        "        elif i == 17:\n",
        "            anomaly_count['GuessPassword (attack_type 17)'] = count\n",
        "        elif i == 7:\n",
        "            anomaly_count['FTPWrite (attack_type 7)'] = count\n",
        "        elif i == 6:\n",
        "            anomaly_count['Multihop (attack_type 6)'] = count\n",
        "        else:\n",
        "            anomaly_count['Others'] = anomaly_count.get('Others', 0) + count\n",
        "\n",
        "# Print results\n",
        "print(\"Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(df['label'] == 4, predicted_labels) * 100:.2f}%\")\n",
        "print(f\"True Negatives (TN): {tn}\")\n",
        "print(f\"False Positives (FP): {fp}\")\n",
        "print(f\"False Negatives (FN): {fn}\")\n",
        "print(f\"True Positives (TP): {tp}\")\n",
        "# Print the count and classification of anomalies\n",
        "print(\"Number of Anomalies:\", sum(anomaly_count.values()))\n",
        "print(\"Indices of Anomalies:\", np.where(predicted_labels == 1)[0])\n",
        "print(\"Attack Types of Anomalies:\")\n",
        "for key, value in anomaly_count.items():\n",
        "    print(f\"{key}: {value}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(df['label'] == 4, predicted_labels))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(df['label'] == 4, predicted_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjwEbPOF4EgY",
        "outputId": "70e901f7-ea89-4966-f61f-05066e99e7db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using the trained GAN for anomaly detection...\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "Calculating anomaly scores...\n",
            "Detecting anomalies...\n",
            "Calculating confusion matrix...\n",
            "Counting and classifying anomalies...\n",
            "Results:\n",
            "Accuracy: 96.00%\n",
            "True Negatives (TN): 960\n",
            "False Positives (FP): 40\n",
            "False Negatives (FN): 0\n",
            "True Positives (TP): 0\n",
            "Number of Anomalies: 1000\n",
            "Indices of Anomalies: [254 301 308 312 348 373 381 405 411 440 443 481 540 561 592 597 647 650\n",
            " 693 707 732 739 750 761 770 780 795 812 841 844 853 870 911 925 948 965\n",
            " 966 976 986 991]\n",
            "Attack Types of Anomalies:\n",
            "Normal (attack_type 4): 516\n",
            "Others: 484\n",
            "Confusion Matrix:\n",
            "[[960  40]\n",
            " [  0   0]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       1.00      0.96      0.98      1000\n",
            "        True       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.96      1000\n",
            "   macro avg       0.50      0.48      0.49      1000\n",
            "weighted avg       1.00      0.96      0.98      1000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 5: GUI**"
      ],
      "metadata": {
        "id": "iiHZKDWgAs_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n"
      ],
      "metadata": {
        "id": "o8Hpcbb4Azph",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1688d90c-bd1d-4bb1-dd14-efc1a6fa9091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-4.31.5-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.16.4 (from gradio)\n",
            "  Downloading gradio_client-0.16.4-py3-none-any.whl (315 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.9/315.9 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.23.1)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.7.1)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.4.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Collecting typer<1.0,>=0.12 (from gradio)\n",
            "  Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.16.4->gradio) (2023.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.16.4->gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.14.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.18.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi->gradio)\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi->gradio)\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi->gradio)\n",
            "  Downloading email_validator-2.1.1-py3-none-any.whl (30 kB)\n",
            "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->gradio)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.1)\n",
            "Collecting httptools>=0.5.0 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m110.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=9a9753b8bb2da79eee342ffd8032bcea81a98e32d24ac849dbc395df35c65244\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, uvloop, ujson, tomlkit, shellingham, semantic-version, ruff, python-multipart, python-dotenv, orjson, httptools, h11, dnspython, aiofiles, watchfiles, uvicorn, starlette, httpcore, email_validator, typer, httpx, gradio-client, fastapi-cli, fastapi, gradio\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.9.4\n",
            "    Uninstalling typer-0.9.4:\n",
            "      Successfully uninstalled typer-0.9.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
            "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 dnspython-2.6.1 email_validator-2.1.1 fastapi-0.111.0 fastapi-cli-0.0.4 ffmpy-0.3.2 gradio-4.31.5 gradio-client-0.16.4 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 orjson-3.10.3 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.9 ruff-0.4.5 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.37.2 tomlkit-0.12.0 typer-0.12.3 ujson-5.10.0 uvicorn-0.29.0 uvloop-0.19.0 watchfiles-0.21.0 websockets-11.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Load the saved generator model\n",
        "generator_model_path = \"/content/drive/MyDrive/MINI 1/generator_model.h5\"\n",
        "generator = load_model(generator_model_path)\n",
        "\n",
        "# Define the anomaly_detection_interface function\n",
        "def anomaly_detection_interface(dataset_file):\n",
        "    try:\n",
        "        # Load the dataset\n",
        "        df = pd.read_csv(dataset_file.name)\n",
        "\n",
        "        # Encode categorical features\n",
        "        categorical_cols = ['protocol_type', 'service', 'flag', 'label']\n",
        "        for col in categorical_cols:\n",
        "            df[col] = pd.factorize(df[col])[0]\n",
        "\n",
        "        # Scale numerical features\n",
        "        scaler = StandardScaler()\n",
        "        numerical_cols = [col for col in df.columns if col not in categorical_cols]\n",
        "        df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
        "\n",
        "        # Generate synthetic data using the generator\n",
        "        synthetic_data = generator.predict(np.random.normal(0, 1, size=(len(df), generator.input_shape[1])))\n",
        "\n",
        "        # Calculate anomaly scores\n",
        "        anomaly_scores = np.mean(np.abs(synthetic_data - df.values), axis=1)\n",
        "\n",
        "        # Set threshold for anomaly detection\n",
        "        threshold = np.percentile(anomaly_scores, 95)\n",
        "\n",
        "        # Detect anomalies\n",
        "        predicted_labels = anomaly_scores > threshold\n",
        "\n",
        "        # Evaluate model accuracy\n",
        "        binary_labels = np.where(df['label'] == 4, 0, 1)\n",
        "        tn, fp, fn, tp = confusion_matrix(binary_labels, predicted_labels).ravel()\n",
        "        test_accuracy = (tn + tp) / (tn + fp + fn + tp)\n",
        "\n",
        "        # Determine if there are anomalies\n",
        "        presence_of_anomaly = \"Yes\" if np.any(predicted_labels) else \"No\"\n",
        "\n",
        "        # Count and classify anomalies\n",
        "        attack_types = {\n",
        "            0: \"Normal (attack_type 4)\",\n",
        "            15: \"DoS (attack_type 15)\",\n",
        "            9: \"User-to-Root (attack_type 9)\",\n",
        "            10: \"RemoteAccess (attack_type 10)\",\n",
        "            20: \"WarezClient (attack_type 20)\",\n",
        "            8: \"RootKit (attack_type 8)\",\n",
        "            17: \"GuessPassword (attack_type 17)\",\n",
        "            7: \"FTPWrite (attack_type 7)\",\n",
        "            6: \"Multihop (attack_type 6)\"\n",
        "        }\n",
        "        types_of_anomalies = [attack_types[label] for label in df.loc[predicted_labels, 'label'].unique() if label in attack_types]\n",
        "\n",
        "        # Return the results\n",
        "        return {\n",
        "            \"Presence of Anomaly\": presence_of_anomaly,\n",
        "            \"Number of Anomalies\": np.sum(predicted_labels),\n",
        "            \"Types of Anomalies\": types_of_anomalies\n",
        "        }\n",
        "    except Exception as e:\n",
        "        # Print the exception for troubleshooting\n",
        "        print(\"Error:\", e)\n",
        "        # Return a message indicating an error occurred\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "# Create a Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=anomaly_detection_interface,\n",
        "    inputs=\"file\",\n",
        "    outputs=\"json\",\n",
        "    title=\"Anomaly Detection\",\n",
        "    description=\"Upload dataset file.\"\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "interface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 631
        },
        "id": "vtZRVPx2TKUU",
        "outputId": "37f6b3a9-91de-4109-c805-60d21549ee53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://54fbff26fd6f45ee90.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://54fbff26fd6f45ee90.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import logging\n",
        "\n",
        "# Suppressing the warning\n",
        "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Part 1: Loading and Preprocessing Data\n",
        "print(\"Loading and preprocessing the dataset...\")\n",
        "dataset_path = \"/content/drive/MyDrive/MINI 1/KDDTrain.csv\"\n",
        "df = pd.read_csv(dataset_path, nrows=1000)\n",
        "\n",
        "categorical_cols = ['protocol_type', 'service', 'flag', 'label']\n",
        "for col in categorical_cols:\n",
        "    df[col] = pd.factorize(df[col])[0]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "numerical_cols = [col for col in df.columns if col not in categorical_cols]\n",
        "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
        "\n",
        "X_train, X_test = train_test_split(df.values, test_size=0.2, random_state=42)\n",
        "\n",
        "# Part 2: Model Definition and Training\n",
        "def build_generator(latent_dim, output_dim):\n",
        "    input_layer = Input(shape=(latent_dim,))\n",
        "    x = Dense(256, activation='relu')(input_layer)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(output_dim, activation='tanh')(x)\n",
        "    generator = Model(input_layer, x)\n",
        "    return generator\n",
        "\n",
        "def build_discriminator(input_dim):\n",
        "    input_layer = Input(shape=(input_dim,))\n",
        "    x = Dense(256, activation='relu')(input_layer)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(1, activation='sigmoid')(x)\n",
        "    discriminator = Model(input_layer, x)\n",
        "    discriminator.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002), metrics=['accuracy'])\n",
        "    return discriminator\n",
        "\n",
        "def train_gan(generator, discriminator, gan, X_train, latent_dim, epochs, batch_size, loss_weight):\n",
        "    train_accuracy = []\n",
        "    test_accuracy = []\n",
        "    for epoch in range(epochs):\n",
        "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "        gen_data = generator.predict(noise)\n",
        "        real_data = X_train[np.random.randint(0, X_train.shape[0], batch_size)]\n",
        "        discriminator_loss_real = discriminator.train_on_batch(real_data, np.ones((batch_size, 1)))\n",
        "        discriminator_loss_fake = discriminator.train_on_batch(gen_data, np.zeros((batch_size, 1)))\n",
        "        discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
        "\n",
        "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "        generator_loss = gan.train_on_batch(noise, np.ones((batch_size, 1)))\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Epoch {epoch}/{epochs}, Discriminator Loss: {discriminator_loss[0]}, Generator Loss: {generator_loss}\")\n",
        "\n",
        "        if epoch % 5 == 0:\n",
        "            train_accuracy.append(evaluate_accuracy(generator, discriminator, X_train, batch_size))\n",
        "            print(f\"Epoch {epoch}/{epochs}, Train Accuracy: {train_accuracy[-1]}\")\n",
        "\n",
        "    return train_accuracy, test_accuracy\n",
        "\n",
        "def build_gan(generator, discriminator, loss_weight):\n",
        "    discriminator.trainable = False\n",
        "    gan_input = Input(shape=(latent_dim,))\n",
        "    gan_output = discriminator(generator(gan_input))\n",
        "    gan = Model(gan_input, gan_output)\n",
        "    gan.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy', loss_weights=loss_weight)\n",
        "    return gan\n",
        "\n",
        "latent_dim = 20\n",
        "output_dim = df.shape[1]\n",
        "epochs = 100\n",
        "batch_size = 512\n",
        "loss_weight = 0.75\n",
        "\n",
        "generator = build_generator(latent_dim, output_dim)\n",
        "discriminator = build_discriminator(output_dim)\n",
        "\n",
        "generator.save(\"/content/drive/MyDrive/MINI 1/generator_model.h5\")\n",
        "discriminator.save(\"/content/drive/MyDrive/MINI 1/discriminator_model.h5\")\n",
        "print(\"Models Saved Successfully....\")\n",
        "\n",
        "# Part 3: Evaluation and Visualization\n",
        "def evaluate_accuracy(generator, discriminator, X_data, batch_size):\n",
        "    noise = np.random.normal(0, 1, (X_data.shape[0], latent_dim))\n",
        "    gen_data = generator.predict(noise)\n",
        "    real_data = X_data[np.random.randint(0, X_data.shape[0], batch_size)]\n",
        "    synthetic_labels = np.zeros((X_data.shape[0], 1))\n",
        "    real_labels = np.ones((batch_size, 1))\n",
        "    discriminator_accuracy = accuracy_score(np.concatenate([np.ones((batch_size,)), np.zeros((X_data.shape[0]))]),\n",
        "                                             np.concatenate([discriminator.predict(real_data).ravel() >= 0.5, discriminator.predict(gen_data).ravel() >= 0.5]))\n",
        "    return discriminator_accuracy\n",
        "\n",
        "latent_dim = 20\n",
        "batch_size = 512\n",
        "epochs = 100\n",
        "loss_weight = 0.75\n",
        "\n",
        "generator = build_generator(latent_dim, df.shape[1])\n",
        "discriminator = build_discriminator(df.shape[1])\n",
        "gan = build_gan(generator, discriminator, loss_weight)\n",
        "\n",
        "train_accuracy, test_accuracy = train_gan(generator, discriminator, gan, X_train, latent_dim, epochs, batch_size, loss_weight)\n",
        "\n",
        "# Part 4: Classification Report and Analysis\n",
        "print(\"Using the trained GAN for anomaly detection...\")\n",
        "synthetic_data = generator.predict(np.random.normal(0, 1, size=(len(df), latent_dim)))\n",
        "\n",
        "print(\"Calculating anomaly scores...\")\n",
        "anomaly_scores = np.mean(np.abs(synthetic_data - df.values), axis=1)\n",
        "\n",
        "# Adjust the threshold dynamically\n",
        "threshold = anomaly_scores.mean() + 2 * anomaly_scores.std()\n",
        "\n",
        "print(\"Detecting anomalies...\")\n",
        "predicted_labels = anomaly_scores > threshold\n",
        "\n",
        "print(\"Calculating confusion matrix...\")\n",
        "tn, fp, fn, tp = confusion_matrix(df['label'] == 4, predicted_labels).ravel()\n",
        "\n",
        "print(\"Counting and classifying anomalies...\")\n",
        "anomaly_count = {}\n",
        "for i in range(len(df.columns) - 1):\n",
        "    count = df[df['label'] == i].shape[0]\n",
        "    if count > 0:\n",
        "        if i == 0:\n",
        "            anomaly_count['Normal (attack_type 4)'] = count\n",
        "        elif i == 15:\n",
        "            anomaly_count['DoS (attack_type 15)'] = count\n",
        "        elif i == 0:\n",
        "            anomaly_count['Probe (attack_type 0)'] = count\n",
        "        elif i == 9:\n",
        "            anomaly_count['User-to-Root (attack_type 9)'] = count\n",
        "        elif i == 10:\n",
        "            anomaly_count['RemoteAccess (attack_type 10)'] = count\n",
        "        elif i == 20:\n",
        "            anomaly_count['WarezClient (attack_type 20)'] = count\n",
        "        elif i == 8:\n",
        "            anomaly_count['RootKit (attack_type 8)'] = count\n",
        "        elif i == 17:\n",
        "            anomaly_count['GuessPassword (attack_type 17)'] = count\n",
        "        elif i == 7:\n",
        "            anomaly_count['FTPWrite (attack_type 7)'] = count\n",
        "        elif i == 6:\n",
        "            anomaly_count['Multihop (attack_type 6)'] = count\n",
        "        else:\n",
        "            anomaly_count['Others'] = anomaly_count.get('Others', 0) + count\n",
        "\n",
        "print(\"Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(df['label'] == 4, predicted_labels) * 100:.2f}%\")\n",
        "print(f\"True Negatives (TN): {tn}\")\n",
        "print(f\"False Positives (FP): {fp}\")\n",
        "print(f\"False Negatives (FN): {fn}\")\n",
        "print(f\"True Positives (TP): {tp}\")\n",
        "\n",
        "print(\"Number of Anomalies:\", sum(anomaly_count.values()))\n",
        "print(\"Indices of Anomalies:\", np.where(predicted_labels == 1)[0])\n",
        "print(\"Attack Types of Anomalies:\")\n",
        "for key, value in anomaly_count.items():\n",
        "    print(f\"{key}: {value}\")\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(df['label'] == 4, predicted_labels))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(df['label'] == 4, predicted_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbXBql3bMt8s",
        "outputId": "99cfe19b-5815-4a9c-dd1a-1646770a9923"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Loading and preprocessing the dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models Saved Successfully....\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "Epoch 0/100, Discriminator Loss: 0.8783400356769562, Generator Loss: 0.5384610891342163\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 3ms/step\n",
            "Epoch 0/100, Train Accuracy: 0.4344512195121951\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 3ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "Epoch 5/100, Train Accuracy: 0.40625\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "Epoch 10/100, Discriminator Loss: 0.5537185817956924, Generator Loss: 0.4851207733154297\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 3ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "Epoch 10/100, Train Accuracy: 0.39176829268292684\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "Epoch 15/100, Train Accuracy: 0.3940548780487805\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "Epoch 20/100, Discriminator Loss: 0.48529694974422455, Generator Loss: 0.46769022941589355\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "Epoch 20/100, Train Accuracy: 0.4260670731707317\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "Epoch 25/100, Train Accuracy: 0.6638719512195121\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "Epoch 30/100, Discriminator Loss: 0.43277083337306976, Generator Loss: 0.4889828562736511\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "Epoch 30/100, Train Accuracy: 0.9413109756097561\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "Epoch 35/100, Train Accuracy: 0.9786585365853658\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "Epoch 40/100, Discriminator Loss: 0.4119521304965019, Generator Loss: 0.5342110395431519\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "Epoch 40/100, Train Accuracy: 0.9550304878048781\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "Epoch 45/100, Train Accuracy: 0.9222560975609756\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "Epoch 50/100, Discriminator Loss: 0.4000020921230316, Generator Loss: 0.5416527986526489\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "Epoch 50/100, Train Accuracy: 0.9077743902439024\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "Epoch 55/100, Train Accuracy: 0.9672256097560976\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 3ms/step\n",
            "Epoch 60/100, Discriminator Loss: 0.3632650375366211, Generator Loss: 0.5755582451820374\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "Epoch 60/100, Train Accuracy: 0.9839939024390244\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 3ms/step\n",
            "Epoch 65/100, Train Accuracy: 0.9824695121951219\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "Epoch 70/100, Discriminator Loss: 0.33257827535271645, Generator Loss: 0.6121735572814941\n",
            "25/25 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 3ms/step\n",
            "Epoch 70/100, Train Accuracy: 0.9550304878048781\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "Epoch 75/100, Train Accuracy: 0.9626524390243902\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "Epoch 80/100, Discriminator Loss: 0.3287205435335636, Generator Loss: 0.6227816343307495\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "Epoch 80/100, Train Accuracy: 0.979420731707317\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "Epoch 85/100, Train Accuracy: 0.9961890243902439\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "Epoch 90/100, Discriminator Loss: 0.2639494091272354, Generator Loss: 0.7487159967422485\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "Epoch 90/100, Train Accuracy: 0.9961890243902439\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "Epoch 95/100, Train Accuracy: 0.9870426829268293\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "Using the trained GAN for anomaly detection...\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "Calculating anomaly scores...\n",
            "Detecting anomalies...\n",
            "Calculating confusion matrix...\n",
            "Counting and classifying anomalies...\n",
            "Results:\n",
            "Accuracy: 94.30%\n",
            "True Negatives (TN): 943\n",
            "False Positives (FP): 57\n",
            "False Negatives (FN): 0\n",
            "True Positives (TP): 0\n",
            "Number of Anomalies: 1000\n",
            "Indices of Anomalies: [190 221 254 287 301 308 312 342 348 373 375 381 405 411 440 443 481 482\n",
            " 506 517 525 540 559 561 581 592 597 626 647 650 667 693 707 732 739 750\n",
            " 761 770 779 780 792 795 798 812 838 841 844 852 853 870 911 925 948 965\n",
            " 966 976 991]\n",
            "Attack Types of Anomalies:\n",
            "Normal (attack_type 4): 516\n",
            "Others: 484\n",
            "Confusion Matrix:\n",
            "[[943  57]\n",
            " [  0   0]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       1.00      0.94      0.97      1000\n",
            "        True       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.94      1000\n",
            "   macro avg       0.50      0.47      0.49      1000\n",
            "weighted avg       1.00      0.94      0.97      1000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import logging\n",
        "\n",
        "# Suppressing the warning\n",
        "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Part 1: Loading and Preprocessing Data\n",
        "print(\"Loading and preprocessing the dataset...\")\n",
        "dataset_path = \"/content/drive/MyDrive/MINI 1/KDDTrain.csv\"\n",
        "df = pd.read_csv(dataset_path, nrows=1000)\n",
        "\n",
        "categorical_cols = ['protocol_type', 'service', 'flag', 'label']\n",
        "for col in categorical_cols:\n",
        "    df[col] = pd.factorize(df[col])[0]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "numerical_cols = [col for col in df.columns if col not in categorical_cols]\n",
        "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
        "\n",
        "X_train, X_test = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Part 2: Model Definition and Training\n",
        "def build_generator(latent_dim, output_dim):\n",
        "    input_layer = Input(shape=(latent_dim,))\n",
        "    x = Dense(256, activation='relu')(input_layer)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(output_dim, activation='tanh')(x)\n",
        "    generator = Model(input_layer, x)\n",
        "    return generator\n",
        "\n",
        "def build_discriminator(input_dim):\n",
        "    input_layer = Input(shape=(input_dim,))\n",
        "    x = Dense(256, activation='relu')(input_layer)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(1, activation='sigmoid')(x)\n",
        "    discriminator = Model(input_layer, x)\n",
        "    discriminator.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002), metrics=['accuracy'])\n",
        "    return discriminator\n",
        "\n",
        "def train_gan(generator, discriminator, gan, X_train, latent_dim, epochs, batch_size, loss_weight):\n",
        "    train_accuracy = []\n",
        "    test_accuracy = []\n",
        "    for epoch in range(epochs):\n",
        "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "        gen_data = generator.predict(noise)\n",
        "        real_data = X_train.values[np.random.randint(0, X_train.shape[0], batch_size)]\n",
        "        discriminator_loss_real = discriminator.train_on_batch(real_data, np.ones((batch_size, 1)))\n",
        "        discriminator_loss_fake = discriminator.train_on_batch(gen_data, np.zeros((batch_size, 1)))\n",
        "        discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
        "\n",
        "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "        generator_loss = gan.train_on_batch(noise, np.ones((batch_size, 1)))\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Epoch {epoch}/{epochs}, Discriminator Loss: {discriminator_loss[0]}, Generator Loss: {generator_loss}\")\n",
        "\n",
        "        if epoch % 5 == 0:\n",
        "            train_accuracy.append(evaluate_accuracy(generator, discriminator, X_train, batch_size))\n",
        "            test_accuracy.append(evaluate_accuracy(generator, discriminator, X_test, batch_size))\n",
        "            print(f\"Epoch {epoch}/{epochs}, Train Accuracy: {train_accuracy[-1]}, Test Accuracy: {test_accuracy[-1]}\")\n",
        "\n",
        "    return train_accuracy, test_accuracy\n",
        "\n",
        "def build_gan(generator, discriminator, loss_weight):\n",
        "    discriminator.trainable = False\n",
        "    gan_input = Input(shape=(latent_dim,))\n",
        "    gan_output = discriminator(generator(gan_input))\n",
        "    gan = Model(gan_input, gan_output)\n",
        "    gan.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy', loss_weights=loss_weight)\n",
        "    return gan\n",
        "\n",
        "def evaluate_accuracy(generator, discriminator, X_data, batch_size):\n",
        "    noise = np.random.normal(0, 1, (X_data.shape[0], latent_dim))\n",
        "    gen_data = generator.predict(noise)\n",
        "    real_data = X_data.values[np.random.randint(0, X_data.shape[0], batch_size)]\n",
        "    synthetic_labels = np.zeros((X_data.shape[0], 1))\n",
        "    real_labels = np.ones((batch_size, 1))\n",
        "    discriminator_accuracy = accuracy_score(np.concatenate([np.ones((batch_size,)), np.zeros((X_data.shape[0]))]),\n",
        "                                             np.concatenate([discriminator.predict(real_data).ravel() >= 0.5, discriminator.predict(gen_data).ravel() >= 0.5]))\n",
        "    return discriminator_accuracy\n",
        "\n",
        "latent_dim = 20\n",
        "output_dim = df.shape[1]\n",
        "epochs = 200  # Increased number of epochs\n",
        "batch_size = 512\n",
        "loss_weight = 0.75\n",
        "\n",
        "generator = build_generator(latent_dim, output_dim)\n",
        "discriminator = build_discriminator(output_dim)\n",
        "gan = build_gan(generator, discriminator, loss_weight)\n",
        "\n",
        "# Train the GAN model\n",
        "train_accuracy, test_accuracy = train_gan(generator, discriminator, gan, X_train, latent_dim, epochs, batch_size, loss_weight)\n",
        "\n",
        "# Use the trained GAN for anomaly detection\n",
        "print(\"Using the trained GAN for anomaly detection...\")\n",
        "# Generate synthetic data using the generator\n",
        "synthetic_data = generator.predict(np.random.normal(0, 1, size=(len(df), latent_dim)))\n",
        "\n",
        "# Calculate anomaly scores\n",
        "print(\"Calculating anomaly scores...\")\n",
        "anomaly_scores = np.mean(np.abs(synthetic_data - df.values), axis=1)\n",
        "\n",
        "# Dynamically determine threshold based on anomaly scores\n",
        "threshold = np.mean(anomaly_scores) + 1.5 * np.std(anomaly_scores)\n",
        "\n",
        "# Detect anomalies based on the dynamically determined threshold\n",
        "predicted_labels = anomaly_scores > threshold\n",
        "\n",
        "# Count and classify anomalies\n",
        "anomaly_count = {}\n",
        "for i in range(len(df.columns) - 1):\n",
        "    count = df[df['label'] == i].shape[0]\n",
        "    if count > 0:\n",
        "        anomaly_count[f\"Anomaly (attack_type {i})\"] = count\n",
        "\n",
        "# Include normal instances in the count of anomalies\n",
        "anomaly_count['Normal (attack_type 4)'] = (df['label'] == 4).sum()\n",
        "\n",
        "# Print results\n",
        "print(\"Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(df['label'] == 4, predicted_labels) * 100:.2f}%\")\n",
        "print(f\"True Negatives (TN): {tn}\")\n",
        "print(f\"False Positives (FP): {fp}\")\n",
        "print(f\"False Negatives (FN): {fn}\")\n",
        "print(f\"True Positives (TP): {tp}\")\n",
        "print(\"Number of Anomalies:\", sum(anomaly_count.values()))\n",
        "print(\"Indices of Anomalies:\", np.where(predicted_labels == 1)[0])\n",
        "print(\"Attack Types of Anomalies:\")\n",
        "for key, value in anomaly_count.items():\n",
        "    print(f\"{key}: {value}\")\n",
        "\n",
        "# Print confusion matrix and classification report\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(df['label'] == 4, predicted_labels))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(df['label'] == 4, predicted_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zan_H6qLPzHX",
        "outputId": "6cc9ed9a-b58e-4a71-a029-d31e595db14c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Loading and preprocessing the dataset...\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "Epoch 0/200, Discriminator Loss: 0.6960268020629883, Generator Loss: 0.4575808644294739\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 0/200, Train Accuracy: 0.38414634146341464, Test Accuracy: 0.7134831460674157\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 5/200, Train Accuracy: 0.3902439024390244, Test Accuracy: 0.7191011235955056\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "Epoch 10/200, Discriminator Loss: 0.5197523534297943, Generator Loss: 0.40747690200805664\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 10/200, Train Accuracy: 0.3902439024390244, Test Accuracy: 0.7191011235955056\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 15/200, Train Accuracy: 0.3902439024390244, Test Accuracy: 0.7191011235955056\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "Epoch 20/200, Discriminator Loss: 0.461400143802166, Generator Loss: 0.41099846363067627\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 20/200, Train Accuracy: 0.4245426829268293, Test Accuracy: 0.7331460674157303\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 3ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 25/200, Train Accuracy: 0.6920731707317073, Test Accuracy: 0.8890449438202247\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "Epoch 30/200, Discriminator Loss: 0.42316070944070816, Generator Loss: 0.4342738389968872\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 30/200, Train Accuracy: 0.9298780487804879, Test Accuracy: 0.9648876404494382\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 35/200, Train Accuracy: 0.9847560975609756, Test Accuracy: 0.9915730337078652\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "Epoch 40/200, Discriminator Loss: 0.39204542338848114, Generator Loss: 0.4526357054710388\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 3ms/step\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 40/200, Train Accuracy: 0.9611280487804879, Test Accuracy: 0.9817415730337079\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 3ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 45/200, Train Accuracy: 0.8849085365853658, Test Accuracy: 0.9550561797752809\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "Epoch 50/200, Discriminator Loss: 0.397158969193697, Generator Loss: 0.44415920972824097\n",
            "25/25 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 3ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 50/200, Train Accuracy: 0.7835365853658537, Test Accuracy: 0.9030898876404494\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 55/200, Train Accuracy: 0.7347560975609756, Test Accuracy: 0.8862359550561798\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "Epoch 60/200, Discriminator Loss: 0.3903239071369171, Generator Loss: 0.5118195414543152\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 60/200, Train Accuracy: 0.9085365853658537, Test Accuracy: 0.9382022471910112\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 65/200, Train Accuracy: 0.9870426829268293, Test Accuracy: 0.9957865168539326\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "Epoch 70/200, Discriminator Loss: 0.3299211710691452, Generator Loss: 0.7050133347511292\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 70/200, Train Accuracy: 0.9969512195121951, Test Accuracy: 0.9985955056179775\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 75/200, Train Accuracy: 1.0, Test Accuracy: 0.9887640449438202\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "Epoch 80/200, Discriminator Loss: 0.26714683324098587, Generator Loss: 0.8977420330047607\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 80/200, Train Accuracy: 0.9977134146341463, Test Accuracy: 0.9831460674157303\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 85/200, Train Accuracy: 0.9954268292682927, Test Accuracy: 0.976123595505618\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "Epoch 90/200, Discriminator Loss: 0.25687873363494873, Generator Loss: 0.9186739921569824\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 90/200, Train Accuracy: 0.993140243902439, Test Accuracy: 0.9873595505617978\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 95/200, Train Accuracy: 0.9733231707317073, Test Accuracy: 0.9845505617977528\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "Epoch 100/200, Discriminator Loss: 0.33159320056438446, Generator Loss: 0.8476791381835938\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 100/200, Train Accuracy: 0.9588414634146342, Test Accuracy: 0.9691011235955056\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 105/200, Train Accuracy: 0.9588414634146342, Test Accuracy: 0.9508426966292135\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "Epoch 110/200, Discriminator Loss: 0.3539605960249901, Generator Loss: 0.8184401392936707\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 110/200, Train Accuracy: 0.9641768292682927, Test Accuracy: 0.9676966292134831\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 115/200, Train Accuracy: 0.975609756097561, Test Accuracy: 0.976123595505618\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "Epoch 120/200, Discriminator Loss: 0.2968474254012108, Generator Loss: 0.8736460208892822\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 120/200, Train Accuracy: 0.9679878048780488, Test Accuracy: 0.9662921348314607\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 125/200, Train Accuracy: 0.9771341463414634, Test Accuracy: 0.973314606741573\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "Epoch 130/200, Discriminator Loss: 0.2250431701540947, Generator Loss: 1.0272935628890991\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 130/200, Train Accuracy: 0.9771341463414634, Test Accuracy: 0.9719101123595506\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 135/200, Train Accuracy: 0.9725609756097561, Test Accuracy: 0.9747191011235955\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "Epoch 140/200, Discriminator Loss: 0.20496991276741028, Generator Loss: 1.007906436920166\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 140/200, Train Accuracy: 0.9824695121951219, Test Accuracy: 0.9789325842696629\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 145/200, Train Accuracy: 0.9801829268292683, Test Accuracy: 0.9775280898876404\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 3ms/step\n",
            "Epoch 150/200, Discriminator Loss: 0.21919655799865723, Generator Loss: 1.035340666770935\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 150/200, Train Accuracy: 0.9733231707317073, Test Accuracy: 0.9859550561797753\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 3ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 155/200, Train Accuracy: 0.9885670731707317, Test Accuracy: 0.976123595505618\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "Epoch 160/200, Discriminator Loss: 0.19882464408874512, Generator Loss: 1.2022066116333008\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 160/200, Train Accuracy: 0.9878048780487805, Test Accuracy: 0.9957865168539326\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 165/200, Train Accuracy: 0.989329268292683, Test Accuracy: 0.9943820224719101\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "Epoch 170/200, Discriminator Loss: 0.15104564279317856, Generator Loss: 1.3053779602050781\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 170/200, Train Accuracy: 0.989329268292683, Test Accuracy: 0.9887640449438202\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 175/200, Train Accuracy: 0.9969512195121951, Test Accuracy: 0.9831460674157303\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "Epoch 180/200, Discriminator Loss: 0.11069099232554436, Generator Loss: 1.4853999614715576\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 180/200, Train Accuracy: 0.993140243902439, Test Accuracy: 1.0\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 185/200, Train Accuracy: 0.9969512195121951, Test Accuracy: 1.0\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "Epoch 190/200, Discriminator Loss: 0.09343237429857254, Generator Loss: 1.4621080160140991\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 190/200, Train Accuracy: 0.9984756097560976, Test Accuracy: 1.0\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 195/200, Train Accuracy: 0.9961890243902439, Test Accuracy: 1.0\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "Using the trained GAN for anomaly detection...\n",
            "32/32 [==============================] - 0s 1ms/step\n",
            "Calculating anomaly scores...\n",
            "Results:\n",
            "Accuracy: 90.20%\n",
            "True Negatives (TN): 900\n",
            "False Positives (FP): 100\n",
            "False Negatives (FN): 0\n",
            "True Positives (TP): 0\n",
            "Number of Anomalies: 1000\n",
            "Indices of Anomalies: [146 159 173 179 190 193 201 212 214 215 221 227 235 237 254 287 292 301\n",
            " 308 312 342 348 362 373 375 381 399 405 411 414 440 443 474 477 481 482\n",
            " 495 506 517 525 540 559 561 581 582 592 597 611 625 626 634 640 647 650\n",
            " 667 668 693 696 707 732 739 750 753 761 763 770 779 780 792 793 795 796\n",
            " 798 808 812 838 841 844 852 853 855 864 870 876 893 911 915 925 930 948\n",
            " 958 965 966 976 986 991 993 994]\n",
            "Attack Types of Anomalies:\n",
            "Anomaly (attack_type 0): 516\n",
            "Anomaly (attack_type 1): 380\n",
            "Anomaly (attack_type 2): 13\n",
            "Anomaly (attack_type 3): 91\n",
            "Normal (attack_type 4): 0\n",
            "Confusion Matrix:\n",
            "[[902  98]\n",
            " [  0   0]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       1.00      0.90      0.95      1000\n",
            "        True       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.90      1000\n",
            "   macro avg       0.50      0.45      0.47      1000\n",
            "weighted avg       1.00      0.90      0.95      1000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}